# Infinite-GANs for Synthetic Urban Scene Generation

This repository explores the use of **Neural SDEs as Infinite-Dimensional GANs** for generating synthetic data, with the goal of producing **urban scene data**. The codebase supports training, sample generation, and evaluation using **Wasserstein distance**, with tracking via [Weights & Biases](https://wandb.ai/).

> Originally developed and tested on [UT Austin's TACC cluster](https://www.tacc.utexas.edu/), but can be run locally.

## ğŸ”¬ Background

This project builds on the paper:

> **Neural SDEs as Infinite-Dimensional GANs**  
> _Patrick Kidger et al._  
> [arXiv:2209.12894](https://arxiv.org/abs/2209.12894)

The architecture leverages a **Neural SDE-based generator** and **Neural CDE-based discriminator**, enabling data generation in function space rather than fixed-dimensional representations.

## ğŸš€ Features

-   âœ”ï¸ Infinite-dimensional GAN framework (SDE/CDE architecture)
-   ğŸ§  Neural SDE Generator + Neural CDE Discriminator
-   ğŸ“‰ Wasserstein loss implementation
-   ğŸ“Š Real-time experiment tracking with Weights & Biases
-   ğŸ–¼ï¸ Synthetic sample generation + image logging
-   âš™ï¸ Modular config files via YAML config files
-   ğŸ§® Batch job support for UT TACC SLURM cluster

## ğŸ“ Project Structure

```
infinite-gans/
â”œâ”€â”€ _Documentation/       # Markdown documents
â”‚   â”œâ”€â”€ problem_statement.md # Formulation of project goal
â”‚   â”œâ”€â”€ breakdown_ryan.md    # Infinite GAN breakdown by Ryan Roby
â”‚   â”œâ”€â”€ datasets.md          # Overview of included datasets
â”‚   â”œâ”€â”€ demo.md              # Showcase of current results
â”‚   â””â”€â”€ tasks.md             # Project tasks timeline
â”œâ”€â”€ src/                  # Core implementation
â”‚   â”œâ”€â”€ run.py               # Command-line interface
â”‚   â”œâ”€â”€ train.py             # Training loop
â”‚   â”œâ”€â”€ data.py              # Real data loader
â”‚   â”œâ”€â”€ generator.py         # Generator (Neural SDE)
â”‚   â”œâ”€â”€ discriminator.py     # Discriminator (Neural CDE)
â”‚   â”œâ”€â”€ losses.py            # Wasserstein loss
â”‚   â”œâ”€â”€ logging.py           # Sample logging
â”‚   â””â”€â”€ utils.py             # Helper methods
â”œâ”€â”€ confs/                # Configuration files
â”‚   â”œâ”€â”€ default.yaml         # Default parameters
â”‚   â”œâ”€â”€ {dataset}.yaml       # Dataset-specific configs
â”‚   â””â”€â”€ {dataset}_basic.yaml # Simplified logic configs
â”œâ”€â”€ data/                 # Datasets
â”œâ”€â”€ sbatch/               # SLURM batch scripts for TACC
â””â”€â”€ figures/              # Figures for documentation
```

## ğŸ› ï¸ Installation

1. Clone the repository:

    ```bash
    git clone https://github.com/briankim31415/3infgan.git
    cd 3infgan
    ```

2. Create a virtual environment and install dependencies:
    ```bash
    python -m venv venv
    source venv/bin/activate
    pip install -r requirements.txt
    ```

### ğŸ“Š Setup Weights & Biases API (on Linux/macOS)

1. Add your Weights & Biases API key to your shell config file as an environment variable:

    ```bash
    export WANDB_API_KEY=your_api_key_here
    ```

2. Apply the changes:

    ```bash
    source ~/.bashrc  # or source ~/.zshrc
    ```

3. Verify environment variable is set correctly:

    ```bash
    # In the Terminal
    echo $WANDB_API_KEY
    ```

    ```python
    # In Python
    import os
    print(os.getenv("WANDB_API_KEY"))
    ```

## ğŸ§ª Running the Code

### â–¶ï¸ Local Training

```bash
python -m src.run   # Generates Ornstein-Uhlenbeck process by default
```

Optional flags:

-   ` --cfg_name=<config_name>`: Specify a config file to run.
-   `--use_wandb`: Enable Weights & Biases logging.
-   `--online`: Set Weights & Biases mode to online.
-   `--cfg_name`: Specify a config from `confs/`.

Example:

```bash
python -m src.run --cfg_name=weather.yaml --use_wandb --online
```

### ğŸ§¬ TACC Cluster (SLURM)

To run on the UT TACC cluster:

```bash
cd sbatch/
sbatch <job_file>.sbatch
```

Edit the `.sbatch` file to point to the config and parameters you want to use.

### âš™ï¸ Config Directory Structure

Each config file begins with the data source name. In the case of the Ornstein-Uhlenbeck process, it is set as the `default` data source. There are 2 types of configuration files per data source:

-   `{data_source}.yaml` runs the expanded training logic with 5 discriminator updates per generator update.
-   `{data_source}_basic.yaml` runs the basic training logic with 1 discriminator update per generator update.

The `simple` designation for the `geolife` dataset tests performance on only 1 column of the dataset for validation purposes.

## ğŸ“š Citation

If you use this codebase, please cite the original work:

```
@article{kidger2022neural,
  title={Neural SDEs as Infinite-Dimensional GANs},
  author={Kidger, Patrick and Foster, James and Lyons, Terry and Salvi, Corrado},
  journal={arXiv preprint arXiv:2209.12894},
  year={2022}
}
```
